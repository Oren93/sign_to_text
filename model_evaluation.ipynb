{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models training\n",
    "In this notebook we train and analyze multiple models, compare them and tune them to get the best results. We will work with a small subset due to low hardware availability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Unsupervised\n",
    "We first try and distinguish the words without letting the model know the labels.\n",
    "\n",
    "# 1.1 Dynamic Time Wrapping and KMeans (DTW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Kernel restart you can sgtart here.\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "with open('landmarks_subset_proccessed.pkl', 'rb') as file:\n",
    "    subset_landmarks = pickle.load(file)\n",
    "\n",
    "data_info = pd.read_csv('video_labels.csv',dtype={'video_id': object})\n",
    "subset_words = ['tall', 'man', 'red', 'shirt', 'play', 'basketball', 'cold', 'pizza', 'top', 'cheese', 'taste',\n",
    "                'delicious', 'lazy', 'afternoon', 'dark', 'room', 'small', 'lamp', 'empty',\n",
    "                'big', 'dog', 'walk', 'beautiful', 'every', 'morning', 'short',\n",
    "                'woman', 'wear', 'dress', 'have', 'beautiful', 'daughter']\n",
    "\n",
    "POSE = np.hstack((np.ones(33), np.zeros(21+21+468))) == 1\n",
    "LH = np.hstack((np.zeros(33), np.ones(21), np.zeros(21+468))) == 1\n",
    "RH = np.hstack((np.zeros(33+21), np.ones(21), np.zeros(468))) == 1\n",
    "FACE = np.hstack((np.zeros(33+21+21), np.ones(468))) == 1\n",
    "videos_per_word = Counter(data_info.loc[data_info.word.isin(subset_words),'word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_signer_id = pd.array([118, 31, 59, 11, 115, 94, 6, 21, 10, 38, 56, 41, 4, 45, 32, 46, 13, 42, 39, 17, 89, 60, 35, 15, 3, 92, 93, 34, 107, 28, 99, 37, 8, 97, 70, 19, 91, 106, 63, 29, 26, 117, 66, 119, 50, 103, 120, 95, 78, 27, 108, 57, 53, 75, 104, 43, 40, 77, 1, 33, 22, 105, 48, 73, 23])\n",
    "test_signer_id = pd.array([2, 52, 12, 98, 88])\n",
    "validation_signer_id = pd.array([59, 115, 90, 4, 116, 100, 101, 102, 96, 90, 36])\n",
    "\n",
    "train_set = data_info[data_info[\"signer_id\"].isin(train_signer_id)]\n",
    "test_set = data_info[data_info[\"signer_id\"].isin(test_signer_id)]\n",
    "val_set = data_info[data_info[\"signer_id\"].isin(validation_signer_id)]\n",
    "\n",
    "train_subset = train_set[train_set[\"word\"].isin(subset_words)]\n",
    "test_subset = test_set[test_set[\"word\"].isin(subset_words)]\n",
    "val_subset = val_set[val_set[\"word\"].isin(subset_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged = {}\n",
    "x = 0\n",
    "for video in subset_landmarks.keys():\n",
    "    x = x + 1\n",
    "    averaged[video] = subset_landmarks[video][:, LH+RH+POSE, :].mean(axis=0).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     video_id         0         1         2         3         4         5  \\\n",
       "0      62175  0.425838  0.218913 -1.234384  0.449388  0.185427 -1.171990   \n",
       "1      62159  0.412828  0.210151 -0.951068  0.437871  0.172065 -0.896456   \n",
       "2      62160  0.576500  0.282573 -1.076096  0.604648  0.235077 -1.014963   \n",
       "3      62163  0.507248  0.271957 -1.239369  0.535961  0.225712 -1.173363   \n",
       "4      62164  0.417331  0.256031 -1.266485  0.447800  0.210131 -1.184287   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "269    19049  0.316342  0.197806 -0.766256  0.337244  0.157780 -0.719825   \n",
       "270    19051  0.569007  0.269934 -1.521104  0.604298  0.227050 -1.451669   \n",
       "271    19054  0.434736  0.232866 -0.802858  0.455187  0.198367 -0.763336   \n",
       "272    32097  0.395933  0.235503 -1.205327  0.412346  0.198697 -1.146361   \n",
       "273    32094  0.338070  0.195371 -0.766534  0.358131  0.156594 -0.721856   \n",
       "\n",
       "            6         7         8         9        10        11        12  \\\n",
       "0    0.463891  0.186640 -1.172169  0.475146  0.188106 -1.172067  0.405481   \n",
       "1    0.454345  0.171454 -0.896744  0.466296  0.171615 -0.896755  0.385191   \n",
       "2    0.623816  0.233920 -1.015107  0.641813  0.233843 -1.014824  0.556943   \n",
       "3    0.555197  0.225018 -1.173503  0.573526  0.225155 -1.173061  0.485133   \n",
       "4    0.467899  0.207806 -1.184623  0.482417  0.206077 -1.184053  0.385701   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.351687  0.157014 -0.720160  0.363752  0.156604 -0.720200  0.294053   \n",
       "270  0.623854  0.228984 -1.451619  0.640362  0.231267 -1.451188  0.540989   \n",
       "271  0.469223  0.198050 -0.763787  0.483034  0.197484 -0.763622  0.411968   \n",
       "272  0.428189  0.197573 -1.146307  0.443233  0.196739 -1.146230  0.370673   \n",
       "273  0.372587  0.155892 -0.722184  0.385623  0.155683 -0.722260  0.315828   \n",
       "\n",
       "           13        14        15        16        17        18        19  \\\n",
       "0    0.184972 -1.175591  0.391740  0.185876 -1.175642  0.377172  0.186948   \n",
       "1    0.176831 -0.899127  0.368082  0.179418 -0.899119  0.354156  0.182364   \n",
       "2    0.241601 -0.994492  0.543173  0.244748 -0.994579  0.529357  0.248838   \n",
       "3    0.232041 -1.154020  0.472551  0.234811 -1.154107  0.458618  0.238359   \n",
       "4    0.214985 -1.187054  0.365196  0.216042 -1.187099  0.348467  0.217377   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.160964 -0.711462  0.280194  0.162350 -0.711414  0.268655  0.164112   \n",
       "270  0.224506 -1.437923  0.519277  0.224306 -1.437701  0.500102  0.225112   \n",
       "271  0.198616 -0.733336  0.398374  0.199270 -0.733000  0.388648  0.200142   \n",
       "272  0.204090 -1.106894  0.357743  0.206596 -1.107232  0.344612  0.209403   \n",
       "273  0.160669 -0.710112  0.302488  0.162730 -0.710100  0.291819  0.164743   \n",
       "\n",
       "           20        21        22        23        24        25        26  \\\n",
       "0   -1.176172  0.493899  0.208292 -0.706222  0.360242  0.208194 -0.717183   \n",
       "1   -0.899724  0.485748  0.192268 -0.503775  0.339806  0.205907 -0.507434   \n",
       "2   -0.995128  0.674448  0.257017 -0.592928  0.524446  0.276978 -0.491633   \n",
       "3   -1.154587  0.604192  0.249718 -0.720971  0.452838  0.268801 -0.632655   \n",
       "4   -1.187659  0.516421  0.227690 -0.618873  0.328351  0.244803 -0.621420   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.711825  0.382505  0.170796 -0.377766  0.255710  0.182931 -0.330804   \n",
       "270 -1.438182  0.679580  0.263159 -0.921718  0.478781  0.254997 -0.843356   \n",
       "271 -0.733326  0.502298  0.213357 -0.424997  0.372279  0.221102 -0.271373   \n",
       "272 -1.107848  0.473789  0.214321 -0.717351  0.334481  0.223658 -0.535943   \n",
       "273 -0.710550  0.403744  0.172222 -0.396504  0.280139  0.183987 -0.332674   \n",
       "\n",
       "           27        28        29        30        31        32        33  \\\n",
       "0    0.455189  0.262913 -1.059763  0.395729  0.260394 -1.063140  0.594498   \n",
       "1    0.449803  0.256264 -0.802382  0.382365  0.259713 -0.803879  0.605299   \n",
       "2    0.616811  0.333510 -0.921750  0.555705  0.337471 -0.894880  0.818053   \n",
       "3    0.548561  0.324117 -1.074950  0.483669  0.329460 -1.051112  0.748274   \n",
       "4    0.461831  0.300670 -1.055428  0.382862  0.305740 -1.058306  0.652699   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.345791  0.236056 -0.636464  0.290041  0.240724 -0.623895  0.490760   \n",
       "270  0.611054  0.330157 -1.323738  0.525694  0.327756 -1.302656  0.801813   \n",
       "271  0.464230  0.274003 -0.674941  0.407064  0.274082 -0.633478  0.611498   \n",
       "272  0.434644  0.276478 -1.052079  0.375886  0.283202 -1.001736  0.625600   \n",
       "273  0.368154  0.234012 -0.643817  0.312380  0.238958 -0.626142  0.515556   \n",
       "\n",
       "           34        35        36        37        38        39        40  \\\n",
       "0    0.431600 -0.384901  0.256032  0.425333 -0.406766  0.690209  0.743013   \n",
       "1    0.443869 -0.237128  0.241384  0.440438 -0.249264  0.713203  0.739191   \n",
       "2    0.529358 -0.397691  0.437728  0.528227 -0.175310  0.996316  0.851544   \n",
       "3    0.531103 -0.480508  0.371946  0.530780 -0.232063  0.942146  0.898215   \n",
       "4    0.485437 -0.226675  0.241596  0.500590 -0.268259  0.835963  0.863806   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.384971 -0.226068  0.175283  0.400772 -0.088980  0.519618  0.677284   \n",
       "270  0.530021 -0.656725  0.343781  0.527059 -0.477384  0.925535  0.849676   \n",
       "271  0.428622 -0.411196  0.277215  0.424232  0.069213  0.617561  0.693519   \n",
       "272  0.451346 -0.488042  0.261749  0.421856 -0.292095  0.679198  0.774394   \n",
       "273  0.387729 -0.261921  0.202216  0.402149 -0.109657  0.551238  0.689319   \n",
       "\n",
       "           41        42        43        44        45        46        47  \\\n",
       "0   -0.380380  0.122832  0.736291 -0.528729  0.638869  0.872330 -0.934651   \n",
       "1   -0.245403  0.132695  0.725970 -0.345662  0.660729  0.853055 -0.763163   \n",
       "2   -0.742728  0.187686  0.699543 -0.579924  0.735429  0.936337 -1.319230   \n",
       "3   -0.857013  0.113539  0.759538 -0.574013  0.649842  0.867858 -1.536359   \n",
       "4   -0.659631  0.091409  0.868863 -0.732717  0.678940  0.760069 -1.674089   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.353790  0.100854  0.674470 -0.260336  0.428563  0.761084 -0.839432   \n",
       "270 -1.137933  0.156186  0.884009 -0.871336  0.761868  0.828455 -2.010663   \n",
       "271 -0.886681  0.076031  0.698318 -0.376002  0.317259  0.620009 -1.482017   \n",
       "272 -0.492323  0.086984  0.352837 -0.911712  0.688633  1.000683 -0.730496   \n",
       "273 -0.274869  0.140853  0.662962 -0.340166  0.451653  0.840034 -0.541366   \n",
       "\n",
       "           48        49        50        51        52        53        54  \\\n",
       "0    0.205181  0.864014 -1.185641  0.639018  0.941911 -1.073420  0.215785   \n",
       "1    0.177501  0.816142 -0.969601  0.649388  0.908509 -0.884725  0.188047   \n",
       "2    0.272010  0.764109 -1.492804  0.663836  0.987707 -1.471677  0.303411   \n",
       "3    0.245226  0.751623 -1.490091  0.566453  0.898932 -1.695593  0.295477   \n",
       "4    0.204004  0.729053 -1.829703  0.631595  0.780123 -1.875132  0.238815   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.139015  0.743888 -0.881305  0.411048  0.808005 -0.974635  0.144450   \n",
       "270  0.183583  0.836672 -1.897142  0.721026  0.853767 -2.212762  0.182956   \n",
       "271  0.153297  0.519637 -1.343841  0.245798  0.618904 -1.642166  0.167444   \n",
       "272  0.206660  0.107589 -1.789725  0.688841  1.087828 -0.819488  0.238407   \n",
       "273  0.182926  0.616262 -0.942375  0.434308  0.898489 -0.636469  0.197153   \n",
       "\n",
       "           55        56        57        58        59        60        61  \\\n",
       "0    0.923590 -1.328036  0.606441  0.940698 -1.129532  0.248925  0.908998   \n",
       "1    0.870167 -1.099021  0.622235  0.890122 -0.927523  0.216169  0.849076   \n",
       "2    0.812639 -1.667894  0.625574  0.942146 -1.426969  0.338538  0.784684   \n",
       "3    0.781709 -1.661900  0.533337  0.850913 -1.636208  0.333036  0.753143   \n",
       "4    0.734925 -2.034121  0.593882  0.756314 -1.843881  0.273980  0.701950   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.779279 -1.013494  0.384570  0.795827 -1.008815  0.170297  0.770100   \n",
       "270  0.835244 -2.096800  0.686884  0.840708 -2.187783  0.221624  0.813564   \n",
       "271  0.489868 -1.502441  0.239406  0.580255 -1.587734  0.187174  0.460629   \n",
       "272  0.071769 -2.006108  0.664724  1.073096 -0.917271  0.260969  0.075060   \n",
       "273  0.620060 -1.069221  0.406322  0.886825 -0.674932  0.212636  0.608732   \n",
       "\n",
       "           62        63        64        65        66        67        68  \\\n",
       "0   -1.392810  0.599225  0.913621 -0.969311  0.251042  0.883250 -1.220374   \n",
       "1   -1.157026  0.616551  0.864972 -0.788875  0.221642  0.826162 -1.003930   \n",
       "2   -1.652534  0.644965  0.917855 -1.309400  0.338271  0.768178 -1.510037   \n",
       "3   -1.612234  0.550783  0.834353 -1.519276  0.329219  0.744960 -1.488577   \n",
       "4   -2.024409  0.597771  0.746490 -1.682155  0.277518  0.700167 -1.846864   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -1.059498  0.384184  0.777973 -0.860161  0.177686  0.756503 -0.913425   \n",
       "270 -2.112653  0.691820  0.831086 -2.022757  0.237868  0.816257 -1.930728   \n",
       "271 -1.476760  0.257177  0.580634 -1.463743  0.191026  0.476214 -1.358404   \n",
       "272 -1.953504  0.651635  1.022525 -0.776118  0.257108  0.093475 -1.808659   \n",
       "273 -1.093340  0.406301  0.864944 -0.558078  0.214902  0.604254 -0.967407   \n",
       "\n",
       "           69        70        71        72        73        74        75  \\\n",
       "0    0.523677  0.991291 -0.048663  0.300101  0.990136  0.050975  0.523266   \n",
       "1    0.536581  0.988143 -0.020520  0.302738  0.985016  0.022634  0.539540   \n",
       "2    0.780235  1.159722 -0.069297  0.511077  1.158656  0.072518  0.760529   \n",
       "3    0.711533  1.149287 -0.070377  0.433433  1.154021  0.073795  0.697736   \n",
       "4    0.589078  1.111587 -0.035176  0.292051  1.120911  0.038935  0.585142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.429540  0.948624 -0.056824  0.231188  0.949854  0.058356  0.430521   \n",
       "270  0.727646  1.182153 -0.101815  0.394359  1.166323  0.106562  0.708987   \n",
       "271  0.502752  0.995313 -0.109933  0.284974  0.977256  0.112514  0.500685   \n",
       "272  0.546187  1.008579 -0.087645  0.303567  0.994653  0.089142  0.514754   \n",
       "273  0.455870  0.946307 -0.067622  0.258014  0.950523  0.069153  0.456471   \n",
       "\n",
       "           76        77        78        79        80        81        82  \\\n",
       "0    1.436464  0.115014  0.289797  1.430381  0.243630  0.516702  1.813253   \n",
       "1    1.405871  0.107213  0.294761  1.399871  0.181449  0.530896  1.772140   \n",
       "2    1.644331  0.016941  0.493712  1.631801  0.103282  0.749119  2.071870   \n",
       "3    1.641331  0.014201  0.426787  1.627298  0.070152  0.687036  2.055493   \n",
       "4    1.598714 -0.019835  0.299706  1.587384  0.001834  0.580715  2.026015   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  1.331201 -0.012813  0.228824  1.325409  0.182968  0.435456  1.674128   \n",
       "270  1.706753  0.046204  0.389004  1.701835  0.335653  0.688911  2.165856   \n",
       "271  1.392342  0.054561  0.259628  1.379647  0.460906  0.490940  1.753788   \n",
       "272  1.441685 -0.091620  0.271754  1.424707  0.173750  0.514001  1.841141   \n",
       "273  1.324919 -0.013826  0.259410  1.324479  0.252970  0.463644  1.669194   \n",
       "\n",
       "           83        84        85        86        87        88        89  \\\n",
       "0    0.830726  0.291575  1.813974  0.848695  0.519791  1.864250  0.870083   \n",
       "1    0.747647  0.298444  1.767588  0.720224  0.535482  1.823946  0.782526   \n",
       "2    0.664832  0.495182  2.061798  0.582139  0.758317  2.137050  0.693895   \n",
       "3    0.745184  0.432245  2.049009  0.615831  0.694363  2.117703  0.779513   \n",
       "4    0.630976  0.304894  2.023377  0.485318  0.587215  2.084521  0.650138   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.613358  0.249755  1.672289  0.691806  0.441967  1.719574  0.653383   \n",
       "270  0.906551  0.381626  2.166647  1.065041  0.693297  2.234855  0.951414   \n",
       "271  0.762073  0.268352  1.739048  1.121563  0.497977  1.808313  0.807104   \n",
       "272  0.637590  0.274281  1.822933  0.811428  0.519811  1.891347  0.677092   \n",
       "273  0.595693  0.277517  1.670131  0.800205  0.467767  1.711911  0.634313   \n",
       "\n",
       "           90        91        92        93        94        95        96  \\\n",
       "0    0.287802  1.867352  0.892481  0.483457  1.941626  0.335084  0.320221   \n",
       "1    0.295260  1.821005  0.758439  0.493604  1.895663  0.282480  0.329261   \n",
       "2    0.495464  2.124754  0.610238  0.706854  2.205963  0.106483  0.518572   \n",
       "3    0.431481  2.112007  0.650715  0.651659  2.193279  0.170811  0.466863   \n",
       "4    0.297694  2.087377  0.509759  0.540521  2.162732 -0.029505  0.347018   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.251311  1.721244  0.729264  0.404077  1.793118  0.240044  0.267728   \n",
       "270  0.373753  2.235899  1.118467  0.639000  2.323386  0.239403  0.413562   \n",
       "271  0.266646  1.790886  1.177102  0.455421  1.870176  0.311351  0.282610   \n",
       "272  0.269380  1.874463  0.855128  0.483853  1.964633  0.034725  0.309196   \n",
       "273  0.279507  1.719147  0.842827  0.431130  1.782751  0.226940  0.288430   \n",
       "\n",
       "           97        98        99       100           101       102       103  \\\n",
       "0    1.939507  0.307384  0.241861  0.248460 -3.492012e-08  0.226206  0.252546   \n",
       "1    1.887771  0.233751  0.267826  0.285907 -2.290127e-08  0.255634  0.281021   \n",
       "2    2.206298 -0.005877  0.380290  0.428947  1.075010e-07  0.355499  0.412109   \n",
       "3    2.193121  0.010551  0.554528  0.671844  1.957915e-07  0.505471  0.661244   \n",
       "4    2.155191 -0.216867  0.540303  0.534266 -2.583546e-08  0.498363  0.522677   \n",
       "..        ...       ...       ...       ...           ...       ...       ...   \n",
       "269  1.783838  0.288109  0.203577  0.331510 -1.334435e-07  0.181017  0.332372   \n",
       "270  2.324250  0.351129  0.263201  0.241121  4.239644e-08  0.234317  0.248696   \n",
       "271  1.860744  0.680521  0.291691  0.603923 -3.516923e-07  0.260493  0.622554   \n",
       "272  1.938467  0.206803  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "273  1.779460  0.412287  0.132773  0.272931 -2.104232e-09  0.118594  0.271753   \n",
       "\n",
       "          104       105       106       107       108       109       110  \\\n",
       "0   -0.003506  0.211557  0.261228 -0.006721  0.201822  0.270388 -0.009686   \n",
       "1   -0.004108  0.241901  0.280933 -0.007177  0.231040  0.280586 -0.009786   \n",
       "2   -0.003598  0.326396  0.409240 -0.006719  0.303666  0.405441 -0.010291   \n",
       "3   -0.007351  0.455154  0.652978 -0.014514  0.419982  0.643084 -0.022267   \n",
       "4   -0.006337  0.451292  0.515394 -0.013221  0.417216  0.507388 -0.020054   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.000753  0.158819  0.342034 -0.001213  0.144468  0.355530 -0.003838   \n",
       "270  0.004086  0.211190  0.258354  0.003501  0.195837  0.267892  0.000796   \n",
       "271  0.002358  0.231076  0.625720 -0.000181  0.211574  0.635778 -0.005791   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.003129  0.104581  0.274436  0.003395  0.094934  0.280573  0.002587   \n",
       "\n",
       "          111       112       113       114       115       116       117  \\\n",
       "0    0.193473  0.277068 -0.012926  0.210837  0.252346 -0.010436  0.202623   \n",
       "1    0.223924  0.276554 -0.012909  0.245099  0.283686 -0.009834  0.239953   \n",
       "2    0.288562  0.397770 -0.014328  0.307679  0.442759 -0.002798  0.284921   \n",
       "3    0.393964  0.632598 -0.030683  0.443806  0.660171 -0.022904  0.401264   \n",
       "4    0.392279  0.496181 -0.028029  0.461801  0.515968 -0.020626  0.435887   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.138305  0.368531 -0.005928  0.151078  0.335130 -0.003511  0.140720   \n",
       "270  0.182853  0.275407 -0.002794  0.200719  0.254274  0.002364  0.179579   \n",
       "271  0.198631  0.648257 -0.010019  0.192329  0.571710  0.011624  0.173613   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.088124  0.285839  0.001642  0.100362  0.267045  0.001604  0.085949   \n",
       "\n",
       "          118       119       120       121       122       123       124  \\\n",
       "0    0.264799 -0.016502  0.197086  0.271152 -0.020232  0.192140  0.276219   \n",
       "1    0.291657 -0.015113  0.238032  0.297027 -0.019210  0.236924  0.301641   \n",
       "2    0.462346 -0.008194  0.272914  0.476749 -0.013785  0.264399  0.489156   \n",
       "3    0.667924 -0.037619  0.376367  0.676572 -0.046279  0.355414  0.683626   \n",
       "4    0.525028 -0.034512  0.422354  0.534830 -0.044378  0.410622  0.543084   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.361896 -0.009221  0.146633  0.365940 -0.012081  0.151785  0.362711   \n",
       "270  0.265607 -0.003739  0.165788  0.273046 -0.009664  0.153669  0.278487   \n",
       "271  0.626691 -0.002618  0.193732  0.639677 -0.014422  0.211713  0.633589   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.272858 -0.000917  0.078284  0.276874 -0.002923  0.072995  0.279953   \n",
       "\n",
       "          125       126       127       128       129       130       131  \\\n",
       "0   -0.022918  0.218924  0.252157 -0.012044  0.216277  0.270055 -0.018389   \n",
       "1   -0.021975  0.252025  0.289596 -0.010431  0.246797  0.298546 -0.014957   \n",
       "2   -0.017865  0.315499  0.456665 -0.005079  0.292585  0.475834 -0.008876   \n",
       "3   -0.051851  0.461061  0.671377 -0.028326  0.425716  0.693642 -0.043455   \n",
       "4   -0.051386  0.477783  0.525992 -0.025715  0.450546  0.537652 -0.037069   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.013323  0.159009  0.339889 -0.006552  0.149450  0.368835 -0.011355   \n",
       "270 -0.014403  0.206054  0.255506 -0.004655  0.183618  0.268935 -0.010088   \n",
       "271 -0.019629  0.194249  0.574385  0.004709  0.171828  0.629640 -0.007378   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273 -0.004217  0.101769  0.271153 -0.001925  0.086276  0.276484 -0.003696   \n",
       "\n",
       "          132       133       134       135       136       137       138  \\\n",
       "0    0.216554  0.272241 -0.020142  0.215592  0.271683 -0.021451  0.228326   \n",
       "1    0.245228  0.304045 -0.017838  0.244351  0.308376 -0.020474  0.258355   \n",
       "2    0.280573  0.489140 -0.013298  0.271927  0.500171 -0.016983  0.327108   \n",
       "3    0.403284  0.709963 -0.050543  0.386996  0.722944 -0.055426  0.484902   \n",
       "4    0.435803  0.546964 -0.043953  0.423712  0.554206 -0.050580  0.496112   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.155685  0.370478 -0.011890  0.160538  0.366255 -0.012278  0.168588   \n",
       "270  0.168551  0.276664 -0.016022  0.154769  0.282572 -0.021195  0.215106   \n",
       "271  0.194082  0.641885 -0.013179  0.210610  0.636582 -0.014164  0.198707   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.077963  0.279891 -0.005182  0.071524  0.282484 -0.006442  0.104233   \n",
       "\n",
       "          139       140       141       142       143       144       145  \\\n",
       "0    0.253185 -0.013731  0.227006  0.271132 -0.019805  0.228573  0.268703   \n",
       "1    0.295385 -0.011019  0.253377  0.304208 -0.015398  0.252065  0.309324   \n",
       "2    0.468211 -0.007957  0.305862  0.486067 -0.011397  0.294771  0.497558   \n",
       "3    0.686057 -0.033759  0.464024  0.725480 -0.050297  0.467893  0.739660   \n",
       "4    0.538129 -0.031085  0.470331  0.548436 -0.042576  0.456239  0.555772   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.346109 -0.009696  0.159101  0.372419 -0.014059  0.164512  0.374132   \n",
       "270  0.257546 -0.011845  0.195110  0.269532 -0.017472  0.181047  0.275353   \n",
       "271  0.583099 -0.003807  0.174475  0.635609 -0.014974  0.196598  0.647154   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.276874 -0.005391  0.089349  0.281507 -0.006602  0.081620  0.284097   \n",
       "\n",
       "          146       147       148       149       150       151       152  \\\n",
       "0   -0.018614  0.228632  0.263585 -0.017355  0.237587  0.254781 -0.015627   \n",
       "1   -0.016399  0.251119  0.313210 -0.017312  0.263935  0.300660 -0.011823   \n",
       "2   -0.013921  0.286469  0.506748 -0.016053  0.340737  0.477641 -0.011321   \n",
       "3   -0.052283  0.474105  0.744902 -0.051085  0.510620  0.703566 -0.039559   \n",
       "4   -0.045921  0.443989  0.561244 -0.049176  0.515392  0.551322 -0.036668   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.012330  0.169379  0.370579 -0.010993  0.178692  0.352545 -0.012723   \n",
       "270 -0.022028  0.168229  0.279818 -0.026006  0.227449  0.260520 -0.018720   \n",
       "271 -0.014022  0.212814  0.639813 -0.010084  0.205250  0.596879 -0.012585   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273 -0.007126  0.075553  0.285627 -0.007797  0.107339  0.284091 -0.008642   \n",
       "\n",
       "          153       154       155       156       157       158       159  \\\n",
       "0    0.235537  0.269131 -0.020547  0.235800  0.267795 -0.019793  0.235601   \n",
       "1    0.260259  0.308451 -0.015177  0.259114  0.312774 -0.015165  0.258164   \n",
       "2    0.324510  0.491136 -0.013924  0.315327  0.499162 -0.014261  0.308029   \n",
       "3    0.495173  0.735924 -0.051090  0.495503  0.746451 -0.050925  0.498805   \n",
       "4    0.497331  0.560326 -0.047039  0.487181  0.566807 -0.049155  0.478297   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.169217  0.372581 -0.015736  0.170866  0.378081 -0.014729  0.173770   \n",
       "270  0.216003  0.269507 -0.023874  0.207084  0.274868 -0.026302  0.198253   \n",
       "271  0.179730  0.636463 -0.019195  0.193216  0.646533 -0.015712  0.208198   \n",
       "272  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "273  0.096585  0.288027 -0.009615  0.090011  0.290262 -0.009507  0.084610   \n",
       "\n",
       "          160       161       162       163           164       165       166  \\\n",
       "0    0.263381 -0.018745  0.101190  0.312845  8.558349e-08  0.122388  0.317972   \n",
       "1    0.316204 -0.015238  0.095947  0.331919  7.216936e-08  0.116173  0.332299   \n",
       "2    0.505641 -0.014482  0.144233  0.433194  9.593700e-08  0.169119  0.417541   \n",
       "3    0.749284 -0.049127  0.194330  0.619514  1.132574e-07  0.237190  0.601832   \n",
       "4    0.572316 -0.050934  0.151677  0.457951 -1.934371e-09  0.188702  0.452030   \n",
       "..        ...       ...       ...       ...           ...       ...       ...   \n",
       "269  0.379534 -0.013642  0.074363  0.320027  7.388827e-09  0.092760  0.316409   \n",
       "270  0.279292 -0.028577  0.104546  0.284856 -5.440364e-08  0.128148  0.267973   \n",
       "271  0.642157 -0.009914  0.152594  0.465120 -5.799616e-08  0.171928  0.463191   \n",
       "272  0.000000  0.000000  0.194643  0.085448  3.481404e-07  0.238091  0.096253   \n",
       "273  0.291898 -0.009500  0.117176  0.257292  7.874150e-08  0.130706  0.249459   \n",
       "\n",
       "          167       168       169       170       171       172       173  \\\n",
       "0   -0.002722  0.144222  0.328855 -0.006231  0.160336  0.334367 -0.009454   \n",
       "1   -0.002567  0.136682  0.339461 -0.005127  0.151993  0.343563 -0.007678   \n",
       "2   -0.008929  0.195201  0.413921 -0.015251  0.214729  0.413230 -0.020430   \n",
       "3   -0.009701  0.281903  0.596038 -0.018945  0.313966  0.587600 -0.027043   \n",
       "4   -0.011380  0.222047  0.446321 -0.020503  0.247239  0.439032 -0.029142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.005516  0.108544  0.311847 -0.009142  0.118993  0.307249 -0.012394   \n",
       "270 -0.004931  0.143877  0.242040 -0.011457  0.156337  0.222879 -0.018285   \n",
       "271 -0.015948  0.191051  0.449341 -0.027399  0.207731  0.436984 -0.037392   \n",
       "272 -0.005811  0.273520  0.108947 -0.016494  0.294032  0.127029 -0.027853   \n",
       "273 -0.000185  0.143429  0.241620 -0.002588  0.154398  0.240206 -0.005975   \n",
       "\n",
       "          174       175       176       177       178       179       180  \\\n",
       "0    0.172464  0.332223 -0.012376  0.141061  0.327301 -0.012586  0.153710   \n",
       "1    0.163455  0.341006 -0.010386  0.133928  0.346102 -0.006578  0.143435   \n",
       "2    0.228161  0.411463 -0.025462  0.197900  0.449846 -0.013635  0.218331   \n",
       "3    0.336390  0.577206 -0.035352  0.282946  0.628613 -0.027796  0.317962   \n",
       "4    0.269475  0.429179 -0.038992  0.197059  0.435386 -0.026019  0.205295   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.126666  0.302985 -0.015552  0.101812  0.312027 -0.008742  0.108915   \n",
       "270  0.166373  0.206961 -0.025174  0.128637  0.219889 -0.014320  0.126681   \n",
       "271  0.222539  0.429463 -0.048128  0.173090  0.415685 -0.030025  0.173149   \n",
       "272  0.305998  0.146762 -0.039646  0.286251  0.063816 -0.027878  0.310436   \n",
       "273  0.163352  0.240997 -0.009340  0.140875  0.223273 -0.002152  0.154940   \n",
       "\n",
       "          181       182       183       184       185       186       187  \\\n",
       "0    0.344810 -0.018700  0.161439  0.353721 -0.021771  0.167553  0.360525   \n",
       "1    0.361746 -0.012410  0.147585  0.371545 -0.016795  0.150056  0.378818   \n",
       "2    0.468835 -0.021524  0.230064  0.479869 -0.027504  0.238851  0.488252   \n",
       "3    0.649133 -0.041200  0.336347  0.658735 -0.049374  0.349836  0.665282   \n",
       "4    0.448612 -0.042465  0.209073  0.458987 -0.055760  0.211626  0.465823   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.314459 -0.014417  0.112915  0.316336 -0.018185  0.115480  0.317892   \n",
       "270  0.195135 -0.023089  0.125509  0.180913 -0.028910  0.123639  0.169252   \n",
       "271  0.400648 -0.044050  0.172651  0.388406 -0.053817  0.170381  0.378602   \n",
       "272  0.101219 -0.049869  0.317897  0.133551 -0.064431  0.320216  0.160418   \n",
       "273  0.215442 -0.007879  0.163674  0.214346 -0.012357  0.170388  0.214174   \n",
       "\n",
       "          188       189       190       191       192       193       194  \\\n",
       "0   -0.023842  0.130370  0.330254 -0.014917  0.138673  0.354569 -0.020734   \n",
       "1   -0.019583  0.124764  0.352385 -0.008792  0.134849  0.369244 -0.012973   \n",
       "2   -0.031302  0.188018  0.466610 -0.013616  0.209505  0.486367 -0.018979   \n",
       "3   -0.054243  0.266084  0.649982 -0.028941  0.299842  0.671826 -0.038499   \n",
       "4   -0.064848  0.174089  0.437103 -0.028997  0.184064  0.456251 -0.043079   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.020654  0.092901  0.314086 -0.009600  0.099804  0.325664 -0.016908   \n",
       "270 -0.033717  0.115288  0.223784 -0.020022  0.132271  0.223445 -0.040392   \n",
       "271 -0.060659  0.156949  0.408660 -0.030315  0.152104  0.425560 -0.050705   \n",
       "272 -0.072952  0.264258  0.064135 -0.035591  0.286861  0.105989 -0.057089   \n",
       "273 -0.015308  0.139748  0.225505 -0.006137  0.154839  0.216654 -0.011280   \n",
       "\n",
       "          195       196       197       198       199       200       201  \\\n",
       "0    0.142580  0.361988 -0.021711  0.145932  0.366261 -0.022866  0.118234   \n",
       "1    0.139591  0.379843 -0.015866  0.142744  0.387961 -0.018435  0.115138   \n",
       "2    0.223610  0.497076 -0.022584  0.234307  0.504789 -0.025761  0.178154   \n",
       "3    0.313314  0.676221 -0.041208  0.320011  0.677593 -0.043753  0.247577   \n",
       "4    0.187901  0.466414 -0.052376  0.189326  0.473027 -0.061144  0.153721   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.103395  0.337185 -0.020523  0.105839  0.346154 -0.022377  0.083977   \n",
       "270  0.144501  0.242790 -0.047710  0.150898  0.257520 -0.048542  0.101923   \n",
       "271  0.149803  0.448287 -0.059190  0.146975  0.466678 -0.062639  0.142689   \n",
       "272  0.294428  0.141503 -0.066697  0.296544  0.169702 -0.072106  0.237949   \n",
       "273  0.163308  0.216024 -0.014855  0.169335  0.216042 -0.017213  0.137840   \n",
       "\n",
       "          202       203       204       205       206       207       208  \\\n",
       "0    0.333625 -0.016881  0.123625  0.359419 -0.022172  0.122533  0.357088   \n",
       "1    0.357814 -0.011210  0.125359  0.373773 -0.015273  0.130262  0.383270   \n",
       "2    0.478401 -0.014279  0.197629  0.497003 -0.019300  0.211605  0.506684   \n",
       "3    0.667170 -0.029756  0.274404  0.685232 -0.038292  0.278471  0.682633   \n",
       "4    0.441539 -0.032424  0.161835  0.459328 -0.047742  0.163784  0.468434   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.317044 -0.010933  0.089557  0.325051 -0.017947  0.093570  0.331939   \n",
       "270  0.232448 -0.026072  0.111575  0.220984 -0.041985  0.120780  0.213596   \n",
       "271  0.411147 -0.031312  0.137520  0.423607 -0.049441  0.135837  0.436645   \n",
       "272  0.071276 -0.043275  0.254445  0.111734 -0.064205  0.258257  0.139121   \n",
       "273  0.230728 -0.010477  0.152755  0.223340 -0.015337  0.161664  0.221312   \n",
       "\n",
       "          209       210       211       212       213       214       215  \\\n",
       "0   -0.019468  0.121653  0.351396 -0.017410  0.106024  0.336553 -0.018993   \n",
       "1   -0.016360  0.133852  0.390343 -0.017347  0.105722  0.362257 -0.013831   \n",
       "2   -0.020720  0.222375  0.513422 -0.021798  0.169489  0.485710 -0.015670   \n",
       "3   -0.035685  0.276541  0.678367 -0.033459  0.230092  0.680082 -0.031147   \n",
       "4   -0.052055  0.164840  0.474167 -0.055644  0.136473  0.446987 -0.036637   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269 -0.020005  0.096671  0.337519 -0.020642  0.075806  0.320218 -0.012610   \n",
       "270 -0.046886  0.127500  0.205472 -0.048191  0.090081  0.244026 -0.032113   \n",
       "271 -0.053060  0.133963  0.447468 -0.052939  0.132034  0.418953 -0.033300   \n",
       "272 -0.069319  0.257881  0.158909 -0.070140  0.211844  0.083435 -0.051073   \n",
       "273 -0.017434  0.168006  0.219645 -0.018678  0.135688  0.238100 -0.014896   \n",
       "\n",
       "          216       217       218       219       220       221       222  \\\n",
       "0    0.111252  0.357599 -0.021768  0.111288  0.355044 -0.018947  0.110895   \n",
       "1    0.113920  0.374847 -0.016659  0.118347  0.382308 -0.016364  0.121826   \n",
       "2    0.185052  0.500582 -0.019545  0.196500  0.508441 -0.019227  0.206217   \n",
       "3    0.252265  0.695642 -0.036729  0.255000  0.694920 -0.032694  0.252192   \n",
       "4    0.138644  0.461309 -0.048550  0.137761  0.468532 -0.050083  0.136303   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "269  0.077787  0.321743 -0.017456  0.079125  0.322484 -0.018275  0.080450   \n",
       "270  0.079358  0.228982 -0.042511  0.070091  0.219008 -0.044615  0.061523   \n",
       "271  0.124572  0.415120 -0.045679  0.117575  0.415485 -0.046989  0.111191   \n",
       "272  0.222017  0.119365 -0.066121  0.224639  0.141764 -0.068216  0.224964   \n",
       "273  0.147015  0.233841 -0.018445  0.153841  0.232246 -0.018859  0.158928   \n",
       "\n",
       "          223       224  \n",
       "0    0.348759 -0.016910  \n",
       "1    0.388135 -0.016234  \n",
       "2    0.513421 -0.018767  \n",
       "3    0.692902 -0.029035  \n",
       "4    0.473300 -0.051621  \n",
       "..        ...       ...  \n",
       "269  0.322796 -0.018453  \n",
       "270  0.207884 -0.045484  \n",
       "271  0.416328 -0.046414  \n",
       "272  0.158822 -0.067669  \n",
       "273  0.230601 -0.018878  \n",
       "\n",
       "[274 rows x 226 columns]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_pd.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      62175\n",
       "1      62159\n",
       "2      62160\n",
       "3      62163\n",
       "4      62164\n",
       "       ...  \n",
       "269    19049\n",
       "270    19051\n",
       "271    19054\n",
       "272    32097\n",
       "273    32094\n",
       "Name: video_id, Length: 274, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_pd = pd.DataFrame(averaged).T\n",
    "averaged_pd = averaged_pd.rename_axis('video_id')\n",
    "averaged_pd = averaged_pd.reset_index()\n",
    "averaged_pd[\"video_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_pd = pd.merge(train_subset, averaged_pd, on='video_id', how='left')\n",
    "test_subset_pd = pd.merge(test_subset, averaged_pd, on='video_id', how='left')\n",
    "val_subset_pd = pd.merge(val_subset, averaged_pd, on='video_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   afternoon       1.00      1.00      1.00         1\n",
      "  basketball       0.17      1.00      0.29         1\n",
      "         big       1.00      0.25      0.40         4\n",
      "      cheese       0.00      0.00      0.00         3\n",
      "        cold       1.00      0.67      0.80         3\n",
      "        dark       1.00      0.88      0.93         8\n",
      "    daughter       0.60      1.00      0.75         3\n",
      "   delicious       0.00      0.00      0.00         1\n",
      "         dog       0.17      0.50      0.25         2\n",
      "       dress       0.00      0.00      0.00         0\n",
      "       empty       0.00      0.00      0.00         1\n",
      "       every       0.00      0.00      0.00         1\n",
      "        lazy       0.00      0.00      0.00         1\n",
      "         man       0.50      0.75      0.60         4\n",
      "     morning       0.00      0.00      0.00         1\n",
      "       pizza       0.00      0.00      0.00         1\n",
      "        play       0.00      0.00      0.00         1\n",
      "         red       0.00      0.00      0.00         2\n",
      "        room       0.00      0.00      0.00         1\n",
      "       shirt       0.00      0.00      0.00         3\n",
      "       short       0.00      0.00      0.00         2\n",
      "       small       0.00      0.00      0.00         0\n",
      "        tall       1.00      1.00      1.00         1\n",
      "        walk       0.00      0.00      0.00         2\n",
      "       woman       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.42        50\n",
      "   macro avg       0.30      0.29      0.26        50\n",
      "weighted avg       0.49      0.42      0.41        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_subset_pd.loc[:, 0:224]\n",
    "y_train = train_subset_pd[\"word\"]\n",
    "\n",
    "X_test = val_subset_pd.loc[:, 0:224]\n",
    "y_test = val_subset_pd[\"word\"]\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'kernel' parameter of SVC must be a str among {'sigmoid', 'poly', 'precomputed', 'linear', 'rbf'} or a callable. Got 'nonlinear' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m svm_classifier \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the classifier on the training data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43msvm_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'kernel' parameter of SVC must be a str among {'sigmoid', 'poly', 'precomputed', 'linear', 'rbf'} or a callable. Got 'nonlinear' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='nonlinear', C=1.0)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   afternoon       0.50      1.00      0.67         1\n",
      "  basketball       0.12      1.00      0.22         1\n",
      "   beautiful       0.00      0.00      0.00         0\n",
      "         big       1.00      0.25      0.40         4\n",
      "      cheese       1.00      1.00      1.00         3\n",
      "        cold       1.00      0.67      0.80         3\n",
      "        dark       1.00      0.75      0.86         8\n",
      "    daughter       1.00      0.67      0.80         3\n",
      "   delicious       0.00      0.00      0.00         1\n",
      "         dog       0.00      0.00      0.00         2\n",
      "       empty       1.00      1.00      1.00         1\n",
      "       every       0.50      1.00      0.67         1\n",
      "        have       0.00      0.00      0.00         0\n",
      "        lazy       0.00      0.00      0.00         1\n",
      "         man       0.60      0.75      0.67         4\n",
      "     morning       0.00      0.00      0.00         1\n",
      "       pizza       0.20      1.00      0.33         1\n",
      "        play       0.00      0.00      0.00         1\n",
      "         red       0.50      0.50      0.50         2\n",
      "        room       0.00      0.00      0.00         1\n",
      "       shirt       0.00      0.00      0.00         3\n",
      "       short       1.00      0.50      0.67         2\n",
      "        tall       0.50      1.00      0.67         1\n",
      "       taste       0.00      0.00      0.00         0\n",
      "        walk       1.00      0.50      0.67         2\n",
      "       woman       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.44      0.46      0.40        50\n",
      "weighted avg       0.65      0.54      0.55        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sainity chack with DTW\n",
    "Dynamic Time Wrapping can detect similar motions but its computation is slow, let's take videos of two words only, without the face (which has the majority of landmarks) and check whether it is a good approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play 11\n",
      "basketball 12\n",
      "morning 6\n",
      "tall 13\n",
      "dress 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"play\",\"basketball\",\"morning\",\"tall\",\"dress\",\"beautiful\"]\n",
    "for word in words:\n",
    "    print(word, videos_per_word[word])\n",
    "\n",
    "dtw_landmarks = {}\n",
    "for word in words:\n",
    "    videos = data_info.loc[data_info.word==word,'video_id']\n",
    "    for vid in videos[:2]:\n",
    "        dtw_landmarks[vid] = subset_landmarks[vid][::3,POSE+LH+RH,:] # Exclude augmented videos for now\n",
    "len(dtw_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oren/anaconda3/envs/ai/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['play', 'basketball', 'morning', 'tall', 'dress']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute DTW distance between two sequences\n",
    "def dtw_distance(seq1, seq2):\n",
    "    distance, path = fastdtw(seq1, seq2)\n",
    "    return distance\n",
    "\n",
    "# Function to perform clustering using DTW\n",
    "def dtw_cluster(video_landmarks, num_clusters):\n",
    "    # Flatten the video landmarks into sequences\n",
    "    sequences = [frame.flatten() for frame in video_landmarks]\n",
    "\n",
    "    # Compute pairwise DTW distances\n",
    "    num_frames = len(video_landmarks)\n",
    "    distances = np.zeros((num_frames, num_frames))\n",
    "    for i in range(num_frames):\n",
    "        for j in range(i + 1, num_frames):\n",
    "            distances[i, j] = dtw_distance(sequences[i], sequences[j])\n",
    "            distances[j, i] = distances[i, j]\n",
    "\n",
    "    # Perform KMeans clustering based on DTW distances\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(distances)\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'video_landmarks' is a list of 2D arrays representing landmarks for each frame\n",
    "# You can adjust 'num_clusters' based on your requirements\n",
    "num_clusters = len(words)\n",
    "cluster_labels = dtw_cluster(dtw_landmarks.values(), num_clusters)\n",
    "\n",
    "# Visualize the clustering results\n",
    "plt.scatter(range(len(dtw_landmarks)), [0] * len(dtw_landmarks), c=cluster_labels, cmap='viridis')\n",
    "plt.title('DTW Clustering Results')\n",
    "plt.show()\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
